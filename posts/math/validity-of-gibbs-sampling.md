---
title: ギブスサンプリングが欲しい分布に収束することの説明
published:
tags: ベイズ推論, 機械学習
toc: on
mathjax: on
---

ギブスサンプリングからのサンプル列が,

<!--more-->

{toc}

## 考える問題
ベイズ推論をやると, 確率密度関数は分かっているんだけどどんな分布かは分からないという場面に出くわします.

もし密度関数が「指数が上に凸の2次関数であるような指数関数」だったら, 他の係数などを見ずとも正規分布だと特定できます. しかし共役事前分布を使ったシンプルな場合を除くと, 事後分布は未知の形をしていることが多いです.

そんな未知の密度関数をもつ分布の情報 (平均や分散など) を得るための方法として, **サンプリング** があります. その中でも代表的なのは MCMC の一種であるギブスサンプリング (Gibbs sampling) です.

本記事ではギブスサンプリングが目的の分布からのサンプル列を与える (正確な表現ではない) ことをざっくり説明します.

## サンプリングする目的
確率密度関数は未知の形をしているけれども, **その分布に従うサンプルを得ることはできる**としましょう.

例えば分布 $\mathcal{D}$ に従う独立なサンプル $x_1, x_2, \ldots, x_n$ が得られたら, これを使って $\mathcal{D}$ の平均を次のように近似できます.

$$
\frac{1}{n}\sum_{k = 1}^n x_k
$$

本来平均値は積分を計算する必要がありますが, サンプルさえ得られれば積分計算なしに平均値 (の近似値) を知ることができます.


## サンプリング手法
### MCMC以外
もし累積分布関数の逆関数が分かっているのなら逆関数法というサンプリング手法があります. これを使うと例えば指数分布に従うサンプルを生成することができます. 指数分布とポアソン分布の関連性から, さらにポアソン分布に従うサンプルも生成できます.

正規乱数を生成する方法としてはボックスミュラー法なんてものもあります. ここでは MCMC 以外のサンプリング手法については深入りしませんので, 詳しく知りたい方は以下のサイト等をご参照ください.

- []
- []


### MCMC
MCMC は Markov Chain Monte Carlo の頭文字を取ったものです. 逆関数法やボックスミュラー法は, 欲しい分布 (以後目的分布といいます) に従うサンプルを**直接**得ることができる方法です.

しかしMCMCはそうではありません. MCMC 次の性質を満たす確率変数列 $X_1, X_2,...\ldots$ を生成してくれるものです. ただし $\mathcal{D}$ は目的分布です.

$$
\lim_{n \to \infty}X_n \sim \mathcal{D}
$$

各 $X_n$ は $\mathcal{D}$ に従っているかはわかりませんが, 極限は $\mathcal{D}$ に従います.

そもそもどの意味の極限なのかという疑問はあるかと思いますが, それはあとで解決します.

各 $X_n$ は $\mathcal{D}$ に従っているかはわかりませんが, $n$ が*十分*大きければ, $X_n$ は $\mathcal{D}$ に従っているとみなしてもよさそうです.

つまり何度もサンプリングを繰り返していけば, そのサンプルが従う分布は欲しい分布に近づいていくということです.

上で, ギブスサンプリングが目的の分布からのサンプル列を与えるというのが正確な表現ではないと断りをいれたのは, MCMC がこのような手法だからです.


## ギブスサンプリングはMCMCの一種

ギブスサンプリングでは複数の変数を交互 (もしくは巡回的に) にサンプルします.

### ギブスサンプリング

ここでは確率変数 $\theta_1, \theta_2$ の同時分布が目的分布であるとします. 目的分布の確率密度関数が $p(\theta_1, \theta_2)$ だったとしましょう.


